{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033b5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pl.read_parquet(\"df_without_embeddings.parquet\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87240330",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c81307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the sentence for the medical procedures and previous diagnoses\n",
    "\n",
    "data_final = data_final.with_columns([\n",
    "    pl.concat_str([\n",
    "        pl.lit(\"Tidligere medicinske procedurer: \"),\n",
    "        pl.col(\"Aggregated_Procedures\").fill_null(\"Ingen\"),\n",
    "        pl.lit(\" Tidligere diagnoser: \"),\n",
    "        pl.col(\"Aggregated_Diagnoses\").fill_null(\"Ingen\")\n",
    "    ], separator=\"\").alias(\"Aggregated_Information\")\n",
    "])\n",
    "\n",
    "# Then drop the Aggregated_Procedures and Previous_Diagnoses columns\n",
    "data_final = data_final.drop([\"Aggregated_Procedures\", \"Aggregated_Diagnoses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the column of aggregated information\n",
    "\n",
    "embeddings_data = data_final.select([\"Aggregated_Information\"]).to_series().to_list()\n",
    "\n",
    "# Specify the model2vec multilingual model \n",
    "\n",
    "model = SentenceTransformer(\"minishlab/potion-multilingual-128M\",device = \"cuda\")\n",
    "\n",
    "# Extract the embeddings\n",
    "\n",
    "embeddings = model.encode(embeddings_data,show_progress_bar=True)\n",
    "\n",
    "# Create a list of Series objects, one for each embedding dimension\n",
    "embedding_series = []\n",
    "for i in range(embeddings.shape[1]):\n",
    "    col_name = f\"embed_{i}\"\n",
    "    embedding_series.append(pl.Series(col_name, embeddings[:, i]))\n",
    "\n",
    "# Convert the list of Series into a DataFrame\n",
    "embeddings_df = pl.DataFrame(embedding_series)\n",
    "\n",
    "# Add them to our data\n",
    "\n",
    "data_final = data_final.with_columns(embedding_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e689c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of embedding column names\n",
    "embedding_cols = [f\"embed_{i}\" for i in range(embeddings.shape[1])]\n",
    "\n",
    "# Extract the embedding columns as a numpy array for PCA\n",
    "embeddings_array = data_final.select(embedding_cols).to_numpy()\n",
    "\n",
    "# Initialize and fit PCA\n",
    "pca = PCA(n_components=60)\n",
    "pca_result = pca.fit_transform(embeddings_array)\n",
    "\n",
    "# Create column names for PCA components\n",
    "pca_cols = [f\"pca_{i}\" for i in range(60)]\n",
    "\n",
    "# Create Series objects for each PCA component\n",
    "pca_series = [pl.Series(col, pca_result[:, i]) for i, col in enumerate(pca_cols)]\n",
    "\n",
    "# Drop the original embedding columns and add PCA components\n",
    "data_final = data_final.drop(embedding_cols).with_columns(pca_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a402787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total variance explained by all 60 components\n",
    "total_variance_explained = pca.explained_variance_ratio_.sum()\n",
    "print(f\"Total variance explained by 60 components: {total_variance_explained:.4f} ({total_variance_explained*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c80614",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.write_parquet(\"df_with_embeddings.parquet\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
