{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neccessary libraries\n",
    "\n",
    "import os\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to load the data on diagnoses\n",
    "\n",
    "os.chdir(\"/home/alex/ews/diagnoses\")\n",
    "\n",
    "diagn_embed = pl.read_parquet(\"embed_diagnoses_updated_prevs.parquet\")\n",
    "\n",
    "# Discard the unneccesary columns\n",
    "\n",
    "diagn_embed = diagn_embed.select([col for col in diagn_embed.columns if not col.startswith(\"diagn_embed\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"NA\" with \"Ingen\" in the Previous_Diagnoses column\n",
    "diagn_embed = diagn_embed.with_columns(\n",
    "    pl.col(\"Previous_Diagnoses\").str.replace(\"NA\", \"Ingen\").alias(\"Previous_Diagnoses\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we load the data on procedures\n",
    "\n",
    "os.chdir(\"/home/alex/ews/NEWS2_Evaluation\")\n",
    "\n",
    "procs_embed = pl.read_parquet(\"procs_full_june25.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the other metadata now (this dataframe contains ews scores, age, sex, mortality status, hospital, department name, ...)\n",
    "\n",
    "os.chdir(\"/home/alex/ews/aggregated\")\n",
    "\n",
    "data = pl.read_parquet(\"ews_interventions_24_updated.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fix the datetime variables\n",
    "\n",
    "data = data.with_columns([\n",
    "    (pl.col(\"recorded_time\") - pl.duration(hours=1)).alias(\"recorded_time\"),\n",
    "    (pl.col(\"HOSP_DISCH_TIME\") - pl.duration(hours=1)).dt.replace_time_zone(None).alias(\"HOSP_DISCH_TIME\"),\n",
    "    pl.col(\"deathDate\").dt.replace_time_zone(None).alias(\"deathDate\")\n",
    "])\n",
    "\n",
    "# Drop a column which takes too much size and is not needed\n",
    "\n",
    "data = data.drop(\"Aggregated_Information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now join the data (metadata + procedures)\n",
    "\n",
    "data_final = data.join(procs_embed, on= [\"PT_ID\",\"CSN\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we join the data with the diagnoses\n",
    "\n",
    "data_final = data_final.join(diagn_embed, on= [\"PT_ID\",\"CSN\"], how=\"left\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop more columns not needed\n",
    "\n",
    "data_final = data_final.drop([\"Hemoglobin\",\"Leukocytes\",\"Trombocytes\",\"Kreatinin\", \"ALAT\", \"LDH\", \"Albumin\", \"CRP\", \"Laktak_ab\", \"Troponin\", \"Laktat_vb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are not needed\n",
    "\n",
    "data_final = data_final.drop([\"pca_0\",\"pca_1\",\"pca_2\",\"pca_3\",\"pca_4\",\"pca_5\",\"pca_6\",\"pca_7\",\n",
    "                              \"pca_8\",\"pca_9\",\"pca_10\",\"pca_11\",\"pca_12\",\"pca_13\",\"pca_14\",\"pca_15\",\"pca_16\",\n",
    "                              \"pca_17\",\"pca_18\",\"pca_19\",\"pca_20\",\"pca_21\",\"pca_22\",\"pca_23\",\"pca_24\",\"pca_25\",\"pca_26\",\"pca_27\",\"pca_28\",\"pca_29\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "########### Inspecting the blood test data ###############\n",
    "##########################################################\n",
    "\n",
    "os.chdir(\"/home/alex/ews/NEWS2_Evaluation\")\n",
    "\n",
    "blood_tests = pl.read_parquet(\"blood_tests_imputed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the column names in blood_tests dataframe\n",
    "# Remove the suffix starting from semicolon for columns from 6th position onward\n",
    "# Special handling for Laktat columns\n",
    "\n",
    "# Get current column names\n",
    "old_columns = blood_tests.columns\n",
    "\n",
    "# Create new column names with special handling for Laktat columns\n",
    "new_columns = []\n",
    "for i, col in enumerate(old_columns):\n",
    "    if i < 5:  # Keep first 5 columns as is\n",
    "        new_columns.append(col)\n",
    "    elif col == \"Laktat;P(aB)_imputed\":\n",
    "        new_columns.append(\"Laktat_ab\")\n",
    "    elif col == \"Laktat;P(vB)_imputed\":\n",
    "        new_columns.append(\"Laktat_vb\")\n",
    "    elif ';' in col:  # For all other columns with semicolon, remove suffix\n",
    "        new_columns.append(col.split(';')[0])\n",
    "    else:  # For columns without semicolon, keep as is\n",
    "        new_columns.append(col)\n",
    "\n",
    "# Create a mapping dictionary for renaming\n",
    "column_mapping = {old: new for old, new in zip(old_columns, new_columns)}\n",
    "\n",
    "# Apply the renaming\n",
    "blood_tests = blood_tests.rename(column_mapping)\n",
    "\n",
    "print(\"Old column names:\")\n",
    "for i, col in enumerate(old_columns):\n",
    "    if i >= 5:  # Only show columns that were changed\n",
    "        print(f\"  {col}\")\n",
    "\n",
    "print(\"\\nNew column names:\")\n",
    "for i, col in enumerate(new_columns):\n",
    "    if i >= 5:  # Only show columns that were changed  \n",
    "        print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More modifications\n",
    "\n",
    "current_columns = blood_tests.columns\n",
    "final_columns = []\n",
    "\n",
    "for col in current_columns:\n",
    "    if col == \"C-reaktivt protein [CRP]\":\n",
    "        final_columns.append(\"CRP\")\n",
    "    elif \"[ALAT]\" in col:\n",
    "        final_columns.append(col.replace(\" [ALAT]\", \"\"))\n",
    "    elif \"[LDH]\" in col:\n",
    "        final_columns.append(col.replace(\" [LDH]\", \"\"))\n",
    "    else:\n",
    "        final_columns.append(col)\n",
    "\n",
    "# Create mapping for final renaming\n",
    "final_mapping = {old: new for old, new in zip(current_columns, final_columns)}\n",
    "\n",
    "# Apply the final renaming\n",
    "blood_tests = blood_tests.rename(final_mapping)\n",
    "\n",
    "print(\"Final column renaming:\")\n",
    "for old, new in final_mapping.items():\n",
    "    if old != new:  # Only show columns that changed\n",
    "        print(f\"  {old} â†’ {new}\")\n",
    "\n",
    "print(f\"\\nFinal columns: {blood_tests.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute historical blood test averages for each patient at each recorded time\n",
    "# For each recorded_time, get average of all blood tests that ended before that time\n",
    "\n",
    "# First, let's identify the blood test value columns (excluding the first 5 metadata columns)\n",
    "blood_test_columns = blood_tests.columns[5:]  # All columns from 6th onward\n",
    "print(f\"Blood test columns to average: {blood_test_columns}\")\n",
    "\n",
    "# Create a cross join to get all combinations of data_final records with blood_tests\n",
    "# Then filter where blood_test_end < recorded_time\n",
    "historical_tests = data_final.select([\"PT_ID\", \"Identifier\", \"recorded_time\"]).join(\n",
    "    blood_tests.select([\"PT_ID\", \"Blood_Test_End\"] + blood_test_columns),\n",
    "    on=\"PT_ID\",\n",
    "    how=\"inner\"\n",
    ").filter(\n",
    "    pl.col(\"Blood_Test_End\") < pl.col(\"recorded_time\")\n",
    ")\n",
    "\n",
    "print(f\"Shape of historical tests: {historical_tests.shape}\")\n",
    "\n",
    "# Group by PT_ID and recorded_time, then compute averages for each blood test\n",
    "# We'll use mean() which automatically ignores null values\n",
    "historical_averages = historical_tests.group_by([\"PT_ID\", \"recorded_time\"]).agg([\n",
    "    pl.col(col).mean().alias(f\"avg_{col}\") for col in blood_test_columns\n",
    "])\n",
    "\n",
    "print(f\"Shape of historical averages: {historical_averages.shape}\")\n",
    "\n",
    "# Join the historical averages back to data_final\n",
    "data_final_with_blood_history = data_final.join(\n",
    "    historical_averages,\n",
    "    on=[\"PT_ID\", \"recorded_time\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"Shape of final dataset: {data_final_with_blood_history.shape}\")\n",
    "print(f\"New columns added: {[col for col in data_final_with_blood_history.columns if col.startswith('avg_')]}\")\n",
    "\n",
    "# Display a sample to verify the results\n",
    "data_final_with_blood_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop more unnessary variables for now\n",
    "\n",
    "data_final_with_blood_history = data_final_with_blood_history.drop([\"preds\",\"weights\",\n",
    "                                                                    \"Interventions_24\",\n",
    "                                                                    \"Respirator_Start\",\n",
    "                                                                    \"Respirator_End\",\n",
    "                                                                    \"ITA_Start\",\n",
    "                                                                    \"ITA_End\",\n",
    "                                                                    \"ITA_Department\",\n",
    "                                                                    \"Respiration_Num\",\n",
    "                                                                    \"ITA_Indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop even more variables\n",
    "\n",
    "data_final_with_blood_history = data_final_with_blood_history.drop(\"Interventions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the avg_Troponin T column\n",
    "\n",
    "# Rename the avg_Troponin T column to avg_Troponin\n",
    "data_final_with_blood_history = data_final_with_blood_history.rename({\"avg_Troponin T\": \"avg_Troponin\"})\n",
    "\n",
    "print(f\"Column renamed successfully. New columns: {data_final_with_blood_history.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "############### Inspect the ITA data ###################\n",
    "########################################################\n",
    "\n",
    "ita = pl.read_parquet(\"intensive_care.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new columns based on ITA data:\n",
    "# 1. Previous ICU/Respiratory history (before recorded_time)\n",
    "# 2. Early ICU/Respiratory in current admission (within 24 hours after recorded_time)\n",
    "\n",
    "# First, let's create a column for previous ICU/respiratory history\n",
    "# Check if patient had any ITA_Start or Respirator_Start before recorded_time\n",
    "\n",
    "# Create a cross join to get all combinations of data_final records with ita records\n",
    "previous_icu_check = data_final_with_blood_history.select([\"PT_ID\", \"Identifier\", \"recorded_time\"]).join(\n",
    "    ita.select([\"PT_ID\", \"ITA_Start\", \"Respirator_Start\"]),\n",
    "    on=\"PT_ID\",\n",
    "    how=\"inner\"\n",
    ").filter(\n",
    "    # Check if either ITA_Start or Respirator_Start occurred before recorded_time\n",
    "    (pl.col(\"ITA_Start\") < pl.col(\"recorded_time\")) | \n",
    "    (pl.col(\"Respirator_Start\") < pl.col(\"recorded_time\"))\n",
    ")\n",
    "\n",
    "# Get unique combinations of PT_ID and recorded_time that had previous ICU/respiratory\n",
    "previous_icu_patients = previous_icu_check.select([\"PT_ID\", \"recorded_time\"]).unique()\n",
    "\n",
    "# Add a flag column\n",
    "previous_icu_patients = previous_icu_patients.with_columns(\n",
    "    pl.lit(1).alias(\"previous_icu_respiratory\")\n",
    ")\n",
    "\n",
    "# Join back to main dataframe\n",
    "data_final_with_blood_history = data_final_with_blood_history.join(\n",
    "    previous_icu_patients,\n",
    "    on=[\"PT_ID\", \"recorded_time\"],\n",
    "    how=\"left\"\n",
    ").with_columns(\n",
    "    pl.col(\"previous_icu_respiratory\").fill_null(0)\n",
    ")\n",
    "\n",
    "print(f\"Previous ICU/Respiratory history column added\")\n",
    "\n",
    "# Second, create a column for early ICU/respiratory in current admission\n",
    "# Check if patient had any ITA_Start or Respirator_Start within 24 hours after recorded_time\n",
    "\n",
    "# Calculate 24 hours after recorded_time\n",
    "early_icu_check = data_final_with_blood_history.select([\"PT_ID\", \"Identifier\", \"recorded_time\"]).with_columns(\n",
    "    (pl.col(\"recorded_time\") + pl.duration(hours=24)).alias(\"recorded_time_plus_24h\")\n",
    ").join(\n",
    "    ita.select([\"PT_ID\", \"ITA_Start\", \"Respirator_Start\"]),\n",
    "    on=\"PT_ID\",\n",
    "    how=\"inner\"\n",
    ").filter(\n",
    "    # Check if either ITA_Start or Respirator_Start occurred within 24 hours after recorded_time\n",
    "    ((pl.col(\"ITA_Start\") >= pl.col(\"recorded_time\")) & (pl.col(\"ITA_Start\") <= pl.col(\"recorded_time_plus_24h\"))) |\n",
    "    ((pl.col(\"Respirator_Start\") >= pl.col(\"recorded_time\")) & (pl.col(\"Respirator_Start\") <= pl.col(\"recorded_time_plus_24h\")))\n",
    ")\n",
    "\n",
    "# Get unique combinations that had early ICU/respiratory\n",
    "early_icu_patients = early_icu_check.select([\"PT_ID\", \"recorded_time\"]).unique()\n",
    "\n",
    "# Add a flag column\n",
    "early_icu_patients = early_icu_patients.with_columns(\n",
    "    pl.lit(1).alias(\"early_icu_respiratory_24h\")\n",
    ")\n",
    "\n",
    "# Join back to main dataframe\n",
    "data_final_with_blood_history = data_final_with_blood_history.join(\n",
    "    early_icu_patients,\n",
    "    on=[\"PT_ID\", \"recorded_time\"],\n",
    "    how=\"left\"\n",
    ").with_columns(\n",
    "    pl.col(\"early_icu_respiratory_24h\").fill_null(0)\n",
    ")\n",
    "\n",
    "print(f\"Early ICU/Respiratory (24h) column added\")\n",
    "print(f\"Final dataset shape: {data_final_with_blood_history.shape}\")\n",
    "\n",
    "# Show summary of the new columns\n",
    "print(\"\\nSummary of new columns:\")\n",
    "print(f\"Previous ICU/Respiratory history: {data_final_with_blood_history['previous_icu_respiratory'].sum()} patients out of {data_final_with_blood_history.shape[0]} records\")\n",
    "print(f\"Early ICU/Respiratory (24h): {data_final_with_blood_history['early_icu_respiratory_24h'].sum()} patients out of {data_final_with_blood_history.shape[0]} records\")\n",
    "\n",
    "# Display a sample to verify\n",
    "data_final_with_blood_history.select([\"PT_ID\", \"recorded_time\", \"previous_icu_respiratory\", \"early_icu_respiratory_24h\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "\n",
    "os.chdir(\"/home/alex/ews/NEWS2_Evaluation\")\n",
    "\n",
    "data_final_with_blood_history.write_parquet(\"data_final.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ews_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
