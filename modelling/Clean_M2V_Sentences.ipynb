{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to create the sentences\n",
    "\n",
    "os.chdir(\"/home/alex/ews/NEWS2_Evaluation\")\n",
    "\n",
    "data_final = pl.read_parquet(\"data_final.parquet\")\n",
    "\n",
    "# This creates the sentence for the medical procedures and previous diagnoses\n",
    "\n",
    "data_final = data_final.with_columns([\n",
    "    pl.concat_str([\n",
    "        pl.lit(\"Tidligere medicinske procedurer: \"),\n",
    "        pl.col(\"Aggregated_Procedures\").fill_null(\"Ingen\"),\n",
    "        pl.lit(\" Tidligere diagnoser: \"),\n",
    "        pl.col(\"Previous_Diagnoses\").fill_null(\"Ingen\")\n",
    "    ], separator=\"\").alias(\"Aggregated_Information\")\n",
    "])\n",
    "\n",
    "# Then drop the Aggregated_Procedures and Previous_Diagnoses columns\n",
    "data_final = data_final.drop([\"Aggregated_Procedures\", \"Previous_Diagnoses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the column of aggregated information\n",
    "\n",
    "embeddings_data = data_final.select([\"Aggregated_Information\"]).to_series().to_list()\n",
    "\n",
    "# Specify the model2vec multilingual model \n",
    "\n",
    "model = SentenceTransformer(\"minishlab/potion-multilingual-128M\",device = \"cuda\")\n",
    "\n",
    "# Extract the embeddings\n",
    "\n",
    "embeddings = model.encode(embeddings_data,show_progress_bar=True)\n",
    "\n",
    "# Create a list of Series objects, one for each embedding dimension\n",
    "embedding_series = []\n",
    "for i in range(embeddings.shape[1]):\n",
    "    col_name = f\"embed_{i}\"\n",
    "    embedding_series.append(pl.Series(col_name, embeddings[:, i]))\n",
    "\n",
    "# Convert the list of Series into a DataFrame\n",
    "embeddings_df = pl.DataFrame(embedding_series)\n",
    "\n",
    "# Add them to our data\n",
    "\n",
    "data_final = data_final.with_columns(embedding_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to do PCA on the embedding columns (keep 60 components)\n",
    "\n",
    "# Get the list of embedding column names\n",
    "embedding_cols = [f\"embed_{i}\" for i in range(embeddings.shape[1])]\n",
    "\n",
    "# Extract the embedding columns as a numpy array for PCA\n",
    "embeddings_array = data_final.select(embedding_cols).to_numpy()\n",
    "\n",
    "# Initialize and fit PCA\n",
    "pca = PCA(n_components=60)\n",
    "pca_result = pca.fit_transform(embeddings_array)\n",
    "\n",
    "# Create column names for PCA components\n",
    "pca_cols = [f\"pca_{i}\" for i in range(60)]\n",
    "\n",
    "# Create Series objects for each PCA component\n",
    "pca_series = [pl.Series(col, pca_result[:, i]) for i, col in enumerate(pca_cols)]\n",
    "\n",
    "# Drop the original embedding columns and add PCA components\n",
    "data_final = data_final.drop(embedding_cols).with_columns(pca_series)\n",
    "\n",
    "data_final.write_parquet(\"finalized_with_embeddings.parquet\")\n",
    "\n",
    "# I also want to save the PCA components to a parquet file\n",
    "\n",
    "pca_df = pl.DataFrame(pca_series)\n",
    "\n",
    "pca_df.write_parquet(\"pca_only.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ews_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
