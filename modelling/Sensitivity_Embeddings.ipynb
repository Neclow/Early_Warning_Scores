{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033b5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1a7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pl.read_parquet(\"df_without_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87240330",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c81307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the sentence for the medical procedures and previous diagnoses\n",
    "\n",
    "data_final = data_final.with_columns([\n",
    "    pl.concat_str([\n",
    "        pl.lit(\"Tidligere medicinske procedurer: \"),\n",
    "        pl.col(\"Aggregated_Procedures\").fill_null(\"Ingen\"),\n",
    "        pl.lit(\" Tidligere diagnoser: \"),\n",
    "        pl.col(\"Aggregated_Diagnoses\").fill_null(\"Ingen\")\n",
    "    ], separator=\"\").alias(\"Aggregated_Information\")\n",
    "])\n",
    "\n",
    "# Then drop the Aggregated_Procedures and Previous_Diagnoses columns\n",
    "data_final = data_final.drop([\"Aggregated_Procedures\", \"Aggregated_Diagnoses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "# Select the column of aggregated information\n",
    "embeddings_data = data_final.select([\"Aggregated_Information\"]).to_series().to_list()\n",
    "\n",
    "# Specify the E5 multilingual model \n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large-instruct\", device=\"cuda\")\n",
    "\n",
    "# Define the task in Danish for medical trajectory analysis\n",
    "task_description = \"Givet en patients medicinske forløb med hospitalsbehandlinger og procedurer, repræsenter den til at finde lignende patientforløb\"\n",
    "\n",
    "# Add proper instruction format to each text\n",
    "instructed_texts = [get_detailed_instruct(task_description, text) for text in embeddings_data]\n",
    "\n",
    "# Extract the embeddings with instructed texts\n",
    "embeddings = model.encode(instructed_texts, show_progress_bar=True, normalize_embeddings=True)\n",
    "\n",
    "# Create a list of Series objects, one for each embedding dimension\n",
    "embedding_series = []\n",
    "for i in range(embeddings.shape[1]):\n",
    "    col_name = f\"embed_{i}\"\n",
    "    embedding_series.append(pl.Series(col_name, embeddings[:, i]))\n",
    "\n",
    "# Convert the list of Series into a DataFrame\n",
    "embeddings_df = pl.DataFrame(embedding_series)\n",
    "\n",
    "# Add them to our data\n",
    "data_final = data_final.with_columns(embedding_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of embedding column names\n",
    "embedding_cols = [f\"embed_{i}\" for i in range(embeddings.shape[1])]\n",
    "\n",
    "# Extract the embedding columns as a numpy array for PCA\n",
    "embeddings_array = data_final.select(embedding_cols).to_numpy()\n",
    "\n",
    "# Initialize and fit PCA\n",
    "pca = PCA(n_components=60)\n",
    "pca_result = pca.fit_transform(embeddings_array)\n",
    "\n",
    "# Create column names for PCA components\n",
    "pca_cols = [f\"pca_{i}\" for i in range(60)]\n",
    "\n",
    "# Create Series objects for each PCA component\n",
    "pca_series = [pl.Series(col, pca_result[:, i]) for i, col in enumerate(pca_cols)]\n",
    "\n",
    "# Drop the original embedding columns and add PCA components\n",
    "data_final = data_final.drop(embedding_cols).with_columns(pca_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a402787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total variance explained by all 60 components (76.38%)\n",
    "total_variance_explained = pca.explained_variance_ratio_.sum()\n",
    "print(f\"Total variance explained by 60 components: {total_variance_explained:.4f} ({total_variance_explained*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50c80614",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.write_parquet(\"df_with_embeddings_e5.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.columns"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
