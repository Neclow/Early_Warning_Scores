{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries first\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Access the procedures data\n",
    "\n",
    "procs = pl.read_parquet(\"/home/alex/ews/NEWS2_Evaluation/procedures_newest.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now load the original dataframe with the metadata\n",
    "\n",
    "# First change the current directory to the one where the original dataframe is located\n",
    "\n",
    "os.chdir(\"/home/alex/ews/aggregated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's the original dataframe with the metadata (early warning scores, age, sex, mortality status, department, hospital ...)\n",
    "\n",
    "df = pl.read_parquet(\"ews_interventions_24_updated.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the datetime columns should be converted into the right format\n",
    "\n",
    "df = df.with_columns([\n",
    "    (pl.col(\"recorded_time\") - pl.duration(hours=1)).alias(\"recorded_time\"),\n",
    "    (pl.col(\"HOSP_DISCH_TIME\") - pl.duration(hours=1)).dt.replace_time_zone(None).alias(\"HOSP_DISCH_TIME\"),\n",
    "    pl.col(\"deathDate\").dt.replace_time_zone(None).alias(\"deathDate\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check the exact data types\n",
    "print(\"Procedures data types:\")\n",
    "print(procs.schema)\n",
    "\n",
    "print(\"\\nEWS data types:\")\n",
    "print(df.schema)\n",
    "\n",
    "# Specifically check the datetime columns\n",
    "print(\"\\nProcedure_Date type:\", procs[\"Procedure_Date\"].dtype)\n",
    "print(\"recorded_time type:\", df[\"recorded_time\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract the column of df called \"recorded_time\" and rename\n",
    "\n",
    "ews_dates = df.select(\"PT_ID\",\"CSN\",\"recorded_time\").rename({\"recorded_time\": \"ews_time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now put the ews_dates dataframe into the procedures_newest dataframe after changing back to the original directory\n",
    "\n",
    "os.chdir(\"/home/alex/ews/NEWS2_Evaluation\")\n",
    "\n",
    "# Now join the two dataframes on the CSN column\n",
    "\n",
    "procs = procs.join(ews_dates, on=\"CSN\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get PT_ID for each EWS CSN from the main dataframe\n",
    "ews_with_ptid = df.select(\"PT_ID\", \"CSN\", \"recorded_time\").rename({\"recorded_time\": \"ews_time\"})\n",
    "\n",
    "# Conditional join: join on PT_ID where Procedure_Date < ews_time\n",
    "procs_before_ews = procs.join_where(\n",
    "    ews_with_ptid,\n",
    "    pl.col(\"PT_ID\") == pl.col(\"PT_ID_right\"),\n",
    "    pl.col(\"Procedure_Date\") < pl.col(\"ews_time\")\n",
    ")\n",
    "\n",
    "# Group by EWS CSN and concatenate procedure names with | separator\n",
    "aggregated_procedures = procs_before_ews.group_by(\"CSN_right\").agg(\n",
    "    pl.col(\"Procedurenavn\").str.concat(delimiter=\" | \").alias(\"Aggregated_Procedures\")\n",
    ")\n",
    "\n",
    "# Rename CSN column\n",
    "aggregated_procedures = aggregated_procedures.rename({\"CSN_right\": \"CSN\"})\n",
    "\n",
    "# Join back to all EWS CSNs for complete coverage, keeping PT_ID\n",
    "final_aggregated = ews_with_ptid.select(\"PT_ID\", \"CSN\").unique().join(\n",
    "    aggregated_procedures, on=\"CSN\", how=\"left\"\n",
    ").with_columns(\n",
    "    pl.col(\"Aggregated_Procedures\").fill_null(\"Ingen\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/alex/ews/NEWS2_Evaluation\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to save the final_aggregated dataframe to a parquet file\n",
    "\n",
    "final_aggregated.write_parquet(\"procs_full_june25.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ews_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
