{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    assert torch.cuda.is_available()\n",
    "except (ImportError, AssertionError) as err:\n",
    "    raise ValueError(\"torch should be installed with CUDA enabled.\") from err\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pl.read_parquet(\"df_without_embeddings.parquet\")\n",
    "\n",
    "print(data_final.shape)\n",
    "\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c81307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the sentence for the medical procedures and previous diagnoses\n",
    "\n",
    "data_final = data_final.with_columns([\n",
    "    pl.concat_str([\n",
    "        pl.lit(\"Tidligere medicinske procedurer: \"),\n",
    "        pl.col(\"Aggregated_Procedures\").fill_null(\"Ingen\"),\n",
    "        pl.lit(\" Tidligere diagnoser: \"),\n",
    "        pl.col(\"Aggregated_Diagnoses\").fill_null(\"Ingen\")\n",
    "    ], separator=\"\").alias(\"Aggregated_Information\")\n",
    "])\n",
    "\n",
    "# Then drop the Aggregated_Procedures and Previous_Diagnoses columns\n",
    "data_final = data_final.drop([\"Aggregated_Procedures\", \"Aggregated_Diagnoses\"])\n",
    "\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b6b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the column of aggregated information\n",
    "embeddings_data = data_final.select([\"Aggregated_Information\"]).to_series().to_list()\n",
    "\n",
    "embeddings_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db007e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "print(\"Preparing instructed texts...\")\n",
    "# Define the task in Danish for medical trajectory analysis\n",
    "task_description = \"Givet en patients medicinske forløb med hospitalsbehandlinger og procedurer, repræsenter den til at finde lignende patientforløb\"\n",
    "\n",
    "# Add proper instruction format to each text\n",
    "instructed_texts = [get_detailed_instruct(task_description, text) for text in embeddings_data]\n",
    "\n",
    "instructed_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the E5 multilingual model\n",
    "print(\"Loading model...\")\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large-instruct\")\n",
    "\n",
    "# Extract the embeddings with instructed texts\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = model.encode(\n",
    "    instructed_texts,\n",
    "    batch_size=32,\n",
    "    chunk_size=1024,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    "    device=[\"cuda:0\", \"cuda:1\"]\n",
    ")\n",
    "\n",
    "# Create a list of Series objects, one for each embedding dimension\n",
    "embedding_series = []\n",
    "for i in range(embeddings.shape[1]):\n",
    "    col_name = f\"embed_{i}\"\n",
    "    embedding_series.append(pl.Series(col_name, embeddings[:, i]))\n",
    "\n",
    "# Convert the list of Series into a DataFrame\n",
    "embeddings_df = pl.DataFrame(embedding_series)\n",
    "\n",
    "# Add them to our data\n",
    "data_final = data_final.with_columns(embedding_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of embedding column names\n",
    "embedding_cols = [f\"embed_{i}\" for i in range(embeddings.shape[1])]\n",
    "\n",
    "# Extract the embedding columns as a numpy array for PCA\n",
    "embeddings_array = data_final.select(embedding_cols).to_numpy()\n",
    "\n",
    "# Initialize and fit PCA\n",
    "pca = PCA(n_components=60)\n",
    "pca_result = pca.fit_transform(embeddings_array)\n",
    "\n",
    "# Create column names for PCA components\n",
    "pca_cols = [f\"pca_{i}\" for i in range(60)]\n",
    "\n",
    "# Create Series objects for each PCA component\n",
    "pca_series = [pl.Series(col, pca_result[:, i]) for i, col in enumerate(pca_cols)]\n",
    "\n",
    "# Drop the original embedding columns and add PCA components\n",
    "data_final = data_final.drop(embedding_cols).with_columns(pca_series)\n",
    "\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a402787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total variance explained by all 60 components (76.38%)\n",
    "total_variance_explained = pca.explained_variance_ratio_.sum()\n",
    "print(f\"Total variance explained by 60 components: {total_variance_explained:.4f} ({total_variance_explained*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c80614",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.write_parquet(\"df_with_embeddings_e5.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
